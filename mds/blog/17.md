# Building a simple coding agent infrastructure 

Recently I started using cursor, and I must say is a great tool, I'm sure it improved a lot since the early days but I never tried it. Before Amazon I just used chatgpt/claude web ui and that's it. Then, in Amazon, they started demanding us to use [Amazon Q](https://github.com/aws/amazon-q-developer-cli), their CLI agentic chatbot. 

After reading [this article](https://seconds0.substack.com/p/heres-whats-next-in-agentic-coding) (really recommended to everyone, he explores what could be next for ai coding agents, and usually he has also been right in the past), I became really interested in the agentic coding land so I wanted to understand more about it by building something (that's the best way to learn imho). I'm gonna illustrate what a coding agent is and some smart tricks used to make it efficient.

## pucky

Here it comes [pucky](https://github.com/Graffioh/pucky), a tiny coding agent with minimal dependencies (or at least this is what I'm aiming for) written in python and served as a CLI application.

Of course the name is insipired by Guts mascotte named Puck, from Berserk:

<img src="../../pucky-mascotte.png" alt="pucky-mascotte" width="180">

This was built with `Composer-1`, `GPT-5.1 Codex High` and a bit of my brain :)

### The basics

An agent is basically composed of three components:

- LLM calls (in my case the model is `google-flash-latest` for convenience)
- A while loop
- Function to execute called *Tools*

<img src="../../agent-diagram.svg" alt="agent-diagram-svg" style="width:700px;">

### Tools

A basic coding agent tool set is composed of functions to interact with:
- files (read, write, delete...)
- shell (ls, run things, pwd...) 

That's all you need to make a coding agent, outside of a strong LLM model (agent's brain).

Usually these tools are organized and served using the [**MCP protocol**](https://modelcontextprotocol.io/docs/getting-started/intro), with a server that can be deployed or can be run locally. In my case I didn't really follow that ideology, after all is just a toy project.

### Codebase navigation

My approach for now is really basic.

I started with a simple "read all files", a super inefficient way to manage codebase files, making the context window of the LLM overflow for large projects.

Then with gpt codex I implemented a better way to navigate through the codebase, by:
- Skipping irrelevant files (.env, node_modules, pycache and so on)
- Printing out beforehand a file-tree so the agent can understand the general structure
- Returns chunks/snippets for each match (if searching for something in particular)

This approach is not bad but if you want to search something with natural language (e.g. "Where are we checking if the user has permission to perform x operation?") often it hallucinates or just give the wrong result.

There are more advanced ways, that will be probably furtherly explored for this project, such as a RAG system or [semantic search](https://cursor.com/blog/semsearch) via a trained embedding model.

### Security

Right now there aren't security checks involved outside of confirmation for write/bash operations. Usually these checks are performed via *guardrails*, that prevent the execution of guardrailed functions or such.

A nice (and typical) thing involves the creation of a sandbox isolated environment where the agent can execute the commands without harming the host filesystem.

### Managing Context

This is really important:
- The models have limited context window length, usually ~200k (and for some models, like gemini 2.5 pro, 1M or so)
- If the context is too polluted, the agent will perform bad 

One of the few key techniques is to summarize the context whenever we are approaching the maximum window length, so that in the next prompt we'll flush the current context and append the summarized one. This is called *Compaction*. 

Another important note, is *augmenting* the context, for example by having in it important informations other than the code: git commits, code style and other auxiliary (but important) informations.

### Multi-LLM system

A further improvement would also be to use multiple LLMs that are involved in different part of the workflow such as: Retrieval, Ranking, Code changes, Unit test and PR generation.

This is done usually by an *Orchestrator* that call each LLM based on the needs and the type of the request. This is used to have better granularity and have the "single responsibility" principle applied to the agents.

### Testing

To test the agent, right now I performed a vibe-based testing but for tools I've also added a `test_tools.py` that spin up a CLI program where you can test all the relevant tools functionality. Usually this is really important to do because when it comes to LLM behaviour, you can't do much other than prompting or some smart techniques, but if something is wrong in your tools, well it's completely your fault so it's important to test them.

### UI/UX

Having a good UI/UX is crucial and this is probably where cursor shines nowadays (thanks also to the fact that the team has a lot of money). 

The main agentic tools are split between Cursor-like IDE and Claude Code / Codex CLI softwares.

I really like using the CLI because it's fast for whatever type of codebase, small or super large, where cursor might struggle sometime, but you can't deny the fact that the UX in cursor is way better than a CLI.

### Further read/watch

To read more about cursor-like IDE coding agent, read [this](https://blog.sshh.io/p/how-cursor-ai-ide-works). It's not updated with current/modern approaches but it offers a really good foundation in a few lines. Then you also have [cursor blog posts](https://cursor.com/blog). I'll be using these blog posts/deep research to improve pucky as well.

If you are interested in cursor specifically, go check [Lex podcast with cursor team](https://www.youtube.com/watch?v=oFfVt3S51T4) (even though I prefer Dwarkesh nowadays).